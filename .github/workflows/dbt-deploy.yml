# dbt Deploy to Production Workflow
#
# Deploys changed dbt models + downstream to Snowflake PROD.
# Triggered on merge to main or manual dispatch.
#
# Prerequisites:
#   - Snowflake secrets: SNOWFLAKE_ACCOUNT, SNOWFLAKE__USERNAME,
#     SNOWFLAKE__PRIVATE_KEY, SNOWFLAKE__PASSPHRASE
#   - DBT_ADMIN role with USAGE on warehouse
#
# Snowflake objects:
#   - Role: DBT_ADMIN
#   - Warehouse: WH_NCL_ENGINEERING_XS
#   - Database/Schema: ACCOUNT_ADMIN.DBT_MANAGEMENT
#   - Git repo: REPO__GITHUB__DBT_NCL_ANALYTICS
#   - dbt project: DBT_NCL_ANALYTICS__MAIN

name: dbt Deploy to Production

on:
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - 'models/**'
      - 'macros/**'

jobs:
  deploy-models:
    name: Deploy Changed Models + Downstream
    runs-on: ubuntu-latest
    # Queue deploys sequentially - don't cancel, wait for previous to finish
    concurrency:
      group: dbt-deploy-prod
      cancel-in-progress: false
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          fetch-depth: 0

      - uses: astral-sh/setup-uv@6b9c6063abd6010835644d4c2e1bef4cf5cd0fca # v6
        with:
          version: "0.6.x"

      - name: Get changed models
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "push" ]; then
            # Get changed .sql files directly
            SQL_FILES=$(git diff --name-only --diff-filter=d ${{ github.event.before }} ${{ github.sha }} -- 'models/**/*.sql')
            
            # Get changed .yml/.yaml files and find associated .sql models
            YML_FILES=$(git diff --name-only --diff-filter=d ${{ github.event.before }} ${{ github.sha }} -- 'models/**/*.yml' 'models/**/*.yaml')
            
            # For each yml file, find corresponding sql file(s) in same directory
            YML_DERIVED_SQL=""
            for yml in $YML_FILES; do
              dir=$(dirname "$yml")
              # Check if a .sql file with same base name exists
              base=$(basename "$yml" .yml)
              base=$(basename "$base" .yaml)
              if [ -f "$dir/$base.sql" ]; then
                YML_DERIVED_SQL="$YML_DERIVED_SQL $dir/$base.sql"
              fi
              # Also include all .sql files in same directory (yml may define multiple models)
              for sql in "$dir"/*.sql; do
                [ -f "$sql" ] && YML_DERIVED_SQL="$YML_DERIVED_SQL $sql"
              done
            done
            
            # Combine and deduplicate
            CHANGED=$(echo "$SQL_FILES $YML_DERIVED_SQL" | tr ' ' '\n' | sort -u | tr '\n' ' ')
            [ -n "$YML_FILES" ] && echo "YML changes detected - included associated models"
          else
            CHANGED=""  # Manual trigger = full build
          fi
          COUNT=$(echo "$CHANGED" | wc -w)
          echo "changed_files=$CHANGED" >> $GITHUB_OUTPUT
          echo "file_count=$COUNT" >> $GITHUB_OUTPUT
          echo "Found $COUNT changed model files"

      - name: Setup Snowflake credentials
        env:
          SNOWFLAKE_PRIVATE_KEY: ${{ secrets.SNOWFLAKE__PRIVATE_KEY }}
        run: |
          mkdir -p ~/.snowflake
          printf '%s\n' "$SNOWFLAKE_PRIVATE_KEY" > ~/.snowflake/rsa_key.p8
          chmod 600 ~/.snowflake/rsa_key.p8
          echo "Key file created: $(wc -c < ~/.snowflake/rsa_key.p8) bytes"
          head -1 ~/.snowflake/rsa_key.p8

      - name: Deploy to Snowflake PROD
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE__USERNAME }}
          SNOWFLAKE_PRIVATE_KEY_PASSPHRASE: ${{ secrets.SNOWFLAKE__PASSPHRASE }}
          CHANGED_FILES: ${{ steps.changes.outputs.changed_files }}
          FILE_COUNT: ${{ steps.changes.outputs.file_count }}
        run: |
          uv run --with snowflake-connector-python --with cryptography python << 'EOF'
          import os
          import re
          import sys
          import snowflake.connector

          def validate_identifier(value, pattern=r'^[a-zA-Z0-9_\-/]+$'):
              """Validate identifier to prevent injection."""
              if not value or not re.match(pattern, value):
                  raise ValueError(f"Invalid identifier: {value}")
              return value

          def get_model_name(filepath):
              """Extract and validate model name from filepath."""
              name = filepath.split('/')[-1].replace('.sql', '')
              return validate_identifier(name, r'^[a-zA-Z0-9_]+$')

          from cryptography.hazmat.backends import default_backend
          from cryptography.hazmat.primitives import serialization

          # Load and validate private key
          key_path = os.path.expanduser('~/.snowflake/rsa_key.p8')
          print(f"Key file exists: {os.path.exists(key_path)}")
          if os.path.exists(key_path):
              print(f"Key file size: {os.path.getsize(key_path)} bytes")
              with open(key_path, 'rb') as f:
                  key_data = f.read()
              print(f"Key looks valid: {key_data.startswith(b'-----BEGIN')}")
          else:
              print("ERROR: Key file not found!")
              sys.exit(1)

          passphrase = os.environ.get('SNOWFLAKE_PRIVATE_KEY_PASSPHRASE', '')
          print(f"Passphrase length: {len(passphrase)}")

          # Load private key with cryptography library
          p_key = serialization.load_pem_private_key(
              key_data,
              password=passphrase.encode() if passphrase else None,
              backend=default_backend()
          )
          pkb = p_key.private_bytes(
              encoding=serialization.Encoding.DER,
              format=serialization.PrivateFormat.PKCS8,
              encryption_algorithm=serialization.NoEncryption()
          )

          try:
              conn = snowflake.connector.connect(
                  account=os.environ['SNOWFLAKE_ACCOUNT'],
                  user=os.environ['SNOWFLAKE_USER'],
                  private_key=pkb,
                  role='DBT_ADMIN',
                  database='ACCOUNT_ADMIN',
                  schema='DBT_MANAGEMENT',
                  warehouse='WH_NCL_ENGINEERING_XS'
              )

              cur = conn.cursor()
              cur.execute("USE WAREHOUSE WH_NCL_ENGINEERING_XS")

              print("Fetching git repository...")
              cur.execute("ALTER GIT REPOSITORY REPO__GITHUB__DBT_NCL_ANALYTICS FETCH")
              print("Git fetch complete")

              print("Updating project to main branch...")
              cur.execute("ALTER DBT PROJECT DBT_NCL_ANALYTICS__MAIN ADD VERSION FROM '@REPO__GITHUB__DBT_NCL_ANALYTICS/branches/main'")
              print("Project branch set")

              file_count = int(os.environ.get('FILE_COUNT', 0))
              changed_files = os.environ.get('CHANGED_FILES', '').strip()

              if file_count == 0 or file_count > 50:
                  print(f"Running full build ({file_count} files changed or manual trigger)")
                  args = "build --target snowflake-prod"
              else:
                  # Changed models + downstream (append +)
                  models = [get_model_name(f) + '+' for f in changed_files.split() if f]
                  select = ' '.join(models)
                  print(f"Deploying {file_count} changed models + downstream: {select}")
                  args = f"build --target snowflake-prod --select {select}"

              print(f"Executing: dbt {args}")
              cur.execute(f"EXECUTE DBT PROJECT DBT_NCL_ANALYTICS__MAIN ARGS = '{args}'")

              results = cur.fetchall()
              print("\n--- dbt execution results ---")
              for row in results:
                  print(row[0] if len(row) == 1 else row)
              print("--- end results ---\n")

              # Check for failures in results (avoid false positives from "ERROR=0")
              result_text = str(results)
              if 'job failed' in result_text.lower() or '"command_success": false' in result_text.lower():
                  print("dbt build reported failures", file=sys.stderr)
                  sys.exit(1)

              print("Deployment complete!")

          except Exception as e:
              print(f"Error: {e}", file=sys.stderr)
              sys.exit(1)
          finally:
              if 'cur' in locals(): cur.close()
              if 'conn' in locals(): conn.close()
          EOF

      - name: Cleanup credentials
        if: always()
        run: rm -f ~/.snowflake/rsa_key.p8
